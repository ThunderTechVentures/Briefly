{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install spacy\n",
    "# ! python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated JSON file saved to ../data/final_clean_with_keywords.json\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load the spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"../data/final_clean.json\"\n",
    "output_path = \"../data/final_clean_with_keywords.json\"\n",
    "\n",
    "# Open the JSON file\n",
    "try:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found.\")\n",
    "    exit()\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "    exit()\n",
    "\n",
    "def find_key_phrases(text):\n",
    "    \"\"\"Process text and extract legal key phrases.\"\"\"\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Define key legal terms to search for\n",
    "    key_phrases = [\"amendment\", \"article\", \"act\", \"law\", \"constitution\"]\n",
    "\n",
    "    # Extract key phrases based on predefined terms and entity recognition\n",
    "    extracted_phrases = [token.text for token in doc if token.text in key_phrases or token.ent_type_ in ['LAW', 'ORG']]\n",
    "    \n",
    "    return extracted_phrases\n",
    "\n",
    "# Process each page and add keywords\n",
    "for page in data.get(\"pages\", []):\n",
    "    text = page.get(\"cleaned_text\", \"\")\n",
    "    if text:\n",
    "        keywords = find_key_phrases(text)\n",
    "        page[\"keywords\"] = keywords\n",
    "\n",
    "# Save the updated JSON data with keywords\n",
    "with open(output_path, \"w\") as outfile:\n",
    "    json.dump(data, outfile, indent=4)\n",
    "\n",
    "print(f\"Updated JSON file saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow torch transformers tf-keras numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='tf', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy()  # Convert to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load your data with keywords\n",
    "with open(\"../data/final_clean_with_keywords.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Encode the text for each page\n",
    "for page in data[\"pages\"]:\n",
    "    text = page.get(\"cleaned_text\", \"\")\n",
    "    if text:\n",
    "        page[\"embedding\"] = encode_text(text).tolist()  # Convert numpy array to list for JSON serialization\n",
    "\n",
    "# Save the updated data with embeddings\n",
    "with open(\"../data/with_embeddings.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search(query_text, embeddings):\n",
    "    query_embedding = encode_text(query_text)  # Create embedding for the query\n",
    "    # Ensure the query_embedding is 2D\n",
    "    if query_embedding.ndim == 1:\n",
    "        query_embedding = query_embedding.reshape(1, -1)  # Reshape to 2D\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)  # Compute cosine similarity\n",
    "    similar_indices = np.argsort(similarities[0])[::-1]  # Get indices of most similar pages\n",
    "    return similar_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_list = []\n",
    "embeddings_list = []\n",
    "\n",
    "for page in data['pages']:\n",
    "    cleaned_text_list.append(page['cleaned_text'])\n",
    "    embeddings_list.append(np.array(page['embedding']))\n",
    "    \n",
    "embeddings_list = np.squeeze(embeddings_list)  # Remove single-dimensional entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "187 constitution india part provided election commissioner regional commissioner shall removed office except recommendation chief election commissioner 6 president governor 1 state shall requested election commission make available election commission regional commissioner staff may necessary discharge function conferred election commission clause 1 325 person ineligible inclusion claim included special electoral roll ground religion race caste shall one general electoral roll every territorial constituency election either house parliament house either house legislature state person shall ineligible inclusion roll claim included special electoral roll constituency ground religion race caste sex 326 election house people legislative assembly state basis adult election house people legislative assembly every state shall basis adult suffrage say every person citizen india less 2 eighteen year age date may fixed behalf law made appropriate legislature otherwise disqualified constitution law made appropriate legislature ground unsoundness mind crime corrupt illegal practice shall entitled registered voter election 327 power parliament make provision respect election provision constitution parliament may time time law make provision respect matter relating connection election either house parliament house either house legislature state including preparation electoral roll delimitation constituency matter necessary securing due constitution house house 1 word rajpramukh omitted constitution seventh amendment act 1956 29 sch 2 sub constitution amendment act 1988 2 year\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "311 constitution india seventh schedule 15 war peace 16 foreign jurisdiction 17 citizenship naturalisation alien 18 extradition 19 admission emigration expulsion india passport visa 20 pilgrimage place outside india 21 piracy crime committed high sea air offence law nation committed land high sea air 22 railway 23 highway declared law made parliament national highway 24 shipping navigation inland waterway declared parliament law national waterway regard mechanically propelled vessel rule road waterway 25 maritime shipping navigation including shipping navigation tidal water provision education training mercantile marine regulation education training provided state agency 26 lighthouse including lightship beacon provision safety shipping aircraft 27 port declared law made parliament existing law major port including delimitation constitution power port authority therein 28 port quarantine including hospital connected therewith seaman marine hospital 29 airway aircraft air navigation provision aerodrome regulation organisation air traffic aerodrome provision aeronautical education training regulation education training provided state agency 30 carriage passenger good railway sea air national waterway mechanically propelled vessel\n",
      "\n",
      "\n",
      "314 constitution india seventh schedule 64 institution scientific technical education financed government india wholly part declared parliament law institution national importance 65 union agency institution professional vocational technical training including training police officer b promotion special study research c scientific technical assistance investigation detection crime 66 determination standard institution higher education research scientific technical institution 67 ancient historical monument record archaeological site remains 1 declared law made parliament national importance 68 survey india geological botanical zoological anthropological survey india meteorological organisation 69 census 70 union public service service union public service commission 71 union pension say pension payable government india consolidated fund india 72 election parliament legislature state office president election commission 73 salary allowance member parliament chairman deputy chairman council state speaker deputy speaker house people 74 power privilege immunity house parliament member committee house enforcement attendance person giving evidence producing document committee parliament commission appointed parliament 75 emolument allowance privilege right respect leave absence president governor salary allowance minister union salary allowance right respect leave absence condition service comptroller india 1 sub constitution seventh amendment act 1956 27 declared parliament law\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_relevant_sections(text, keywords):\n",
    "    relevant_sections = []\n",
    "    for line in text.splitlines():\n",
    "        if any(keyword in line.lower() for keyword in keywords):\n",
    "            relevant_sections.append(line)\n",
    "    return \"\\n\".join(relevant_sections)\n",
    "\n",
    "# Example usage\n",
    "# legal_text = \"\"\"\n",
    "# Your legal text here...\n",
    "# \"\"\"\n",
    "keywords = [\"crime\"]\n",
    "for page in data[\"pages\"]:\n",
    "    \n",
    "    \n",
    "    relevant_text = extract_relevant_sections(page[\"cleaned_text\"],keywords)\n",
    "    print(relevant_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant pages for your query:\n",
      "Page 109: part vii state part b first schedule omitted constitution seventh amendment act 1956 29 sch 111\n"
     ]
    }
   ],
   "source": [
    "query = \"what is law about criminals\"  # Replace with your query\n",
    "relevant_indices = search(query, embeddings_list)\n",
    "releavant_indices=relevant_indices[:1]\n",
    "# Display the results\n",
    "print(\"Relevant pages for your query:\")\n",
    "for index in relevant_indices[:1]:  # Display top 5 results\n",
    "    print(f\"Page {index}: {cleaned_text_list[index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
     ]
    }
   ],
   "source": [
    "# Function to summarize text\n",
    "def summarize_text(text, max_length=20, min_length=10):\n",
    "    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Summarize the relevant pages\n",
    "summaries = {}\n",
    "for index in relevant_indices:  # Iterate over relevant indices\n",
    "    text_to_summarize = cleaned_text_list[index]  # Get the text for the relevant page\n",
    "    summaries[index] = summarize_text(text_to_summarize)\n",
    "\n",
    "# Display the summaries\n",
    "for page_index, summary in summaries.items():\n",
    "    print(f\"Summary for Page {page_index}: {summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Using cached notebook-7.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter) (6.29.5)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Using cached jupyterlab-4.2.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (24.1)\n",
      "Requirement already satisfied: psutil in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from ipykernel->jupyter) (6.4.1)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyterlab->jupyter) (3.1.4)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyterlab->jupyter) (75.1.0)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: bleach!=5.0.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (3.0.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Using cached nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbconvert->jupyter) (1.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Collecting anyio (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: sniffio in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (305.1)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: overrides>=5.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.21.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.13)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: websocket-client>=1.7 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: json5>=0.9.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.9.25)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: requests>=2.31 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.20.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.2.3)\n",
      "Requirement already satisfied: fqdn in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in a:\\professional\\programming\\ml\\projects\\legaleagle\\legaleagle\\.conda\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20241003)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab-4.2.5-py3-none-any.whl (11.6 MB)\n",
      "Using cached nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Using cached notebook-7.2.2-py3-none-any.whl (5.0 MB)\n",
      "Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Installing collected packages: terminado, httpcore, beautifulsoup4, babel, attrs, async-lru, anyio, referencing, jupyter-server-terminals, httpx, arrow, argon2-cffi-bindings, jsonschema-specifications, isoduration, argon2-cffi, jsonschema, ipywidgets, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "Successfully installed anyio-4.6.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.4 attrs-24.2.0 babel-2.16.0 beautifulsoup4-4.12.3 httpcore-1.0.6 httpx-0.27.2 ipywidgets-8.1.5 isoduration-20.11.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.2.5 jupyterlab-server-2.27.3 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 notebook-7.2.2 notebook-shim-0.2.4 referencing-0.35.1 terminado-0.18.1\n"
     ]
    }
   ],
   "source": [
    "# ! pip install --upgrade jupyter ipywidgets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
